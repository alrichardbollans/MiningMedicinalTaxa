,recall,class,Model,NS
8,0.1969343552149283,Precise MedCond,Claude,False
9,0.2749083638787071,Approx. MedCond,Claude,False
10,0.2463215258855585,Precise MedEff,Claude,False
11,0.3634877384196185,Approx. MedEff,Claude,False
2,0.1969343552149283,Precise MedCond,Claude,True
3,0.2749083638787071,Approx. MedCond,Claude,True
4,0.2463215258855585,Precise MedEff,Claude,True
5,0.3634877384196185,Approx. MedEff,Claude,True
44,0.2235921359546817,Precise MedCond,Gemini,False
45,0.3045651449516828,Approx. MedCond,Gemini,False
46,0.1771117166212534,Precise MedEff,Gemini,False
47,0.2643051771117166,Approx. MedEff,Gemini,False
38,0.2215928023992002,Precise MedCond,Gemini,True
39,0.3025658113962012,Approx. MedCond,Gemini,True
40,0.1754768392370572,Precise MedEff,Gemini,True
41,0.262125340599455,Approx. MedEff,Gemini,True
68,0.3548817060979673,Precise MedCond,GPT,False
69,0.4711762745751416,Approx. MedCond,GPT,False
70,0.3286103542234332,Precise MedEff,GPT,False
71,0.4942779291553134,Approx. MedEff,GPT,False
62,0.3545484838387204,Precise MedCond,GPT,True
63,0.4708430523158947,Approx. MedCond,GPT,True
64,0.3286103542234332,Precise MedEff,GPT,True
65,0.4942779291553134,Approx. MedEff,GPT,True
80,0.3252249250249917,Precise MedCond,Llama,False
81,0.4648450516494501,Approx. MedCond,Llama,False
82,0.2141689373297002,Precise MedEff,Llama,False
83,0.3760217983651226,Approx. MedEff,Llama,False
74,0.3252249250249917,Precise MedCond,Llama,True
75,0.4648450516494501,Approx. MedCond,Llama,True
76,0.2141689373297002,Precise MedEff,Llama,True
77,0.3760217983651226,Approx. MedEff,Llama,True

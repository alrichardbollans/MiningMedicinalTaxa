,precision,class,Model,NS
6,0.8367217280813215,Precise NER,Claude,False
7,0.8939008894536213,Approx. NER,Claude,False
0,0.8375796178343949,Precise NER,Claude,True
1,0.8949044585987261,Approx. NER,Claude,True
42,0.8973031283710895,Precise NER,Gemini,False
43,0.9216828478964402,Approx. NER,Gemini,False
36,0.9204722655379818,Precise NER,Gemini,True
37,0.9456449097794608,Approx. NER,Gemini,True
54,0.4177057356608479,Precise NER,GNfinder,False
55,0.7066708229426434,Approx. NER,GNfinder,False
48,0.5195868251802768,Precise NER,GNfinder,True
49,0.8793607483921263,Approx. NER,GNfinder,True
66,0.909170305676856,Precise NER,GPT,False
67,0.9301310043668122,Approx. NER,GPT,False
60,0.924545130217624,Precise NER,GPT,True
61,0.9459507670353192,Approx. NER,GPT,True
78,0.8889584637862659,Precise NER,Llama,False
79,0.918388645376748,Approx. NER,Llama,False
72,0.8976960473472839,Precise NER,Llama,True
73,0.9274994715704924,Approx. NER,Llama,True
18,0.2229107086113759,Precise NER,TaxoNERD,False
19,0.2657557462133249,Approx. NER,TaxoNERD,False
12,0.5397999725989862,Precise NER,TaxoNERD,True
13,0.6439238251815317,Approx. NER,TaxoNERD,True
